{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8ce2fc3",
   "metadata": {},
   "source": [
    "Credit Risks\n",
    "Step 1: Download the dataset from the following link:  https://www.openml.org/d/31\n",
    "\n",
    "Step 2: Read the dataset into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "273ac53f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T23:25:21.789251Z",
     "iopub.status.busy": "2025-11-19T23:25:21.789055Z",
     "iopub.status.idle": "2025-11-19T23:25:22.427154Z",
     "shell.execute_reply": "2025-11-19T23:25:22.426371Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.io import arff\n",
    "\n",
    "data, meta = arff.loadarff(\"dataset_31_credit-g.arff\")\n",
    "df = pd.DataFrame(data)\n",
    "#print(df.head(6))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step3_md",
   "metadata": {},
   "source": [
    "Step 3: Feature Selection\n",
    "Choose the features relevant to our analysis.\n",
    "Numeric Attributes: duration, age, residence_since, credit_amount\n",
    "Nominal Attributes: credit_history, employment, job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "step3_code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T23:25:22.429776Z",
     "iopub.status.busy": "2025-11-19T23:25:22.429419Z",
     "iopub.status.idle": "2025-11-19T23:25:22.436456Z",
     "shell.execute_reply": "2025-11-19T23:25:22.435903Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features:\n",
      "   duration   age  residence_since  credit_amount  \\\n",
      "0       6.0  67.0              4.0         1169.0   \n",
      "1      48.0  22.0              2.0         5951.0   \n",
      "2      12.0  49.0              3.0         2096.0   \n",
      "3      42.0  45.0              4.0         7882.0   \n",
      "4      24.0  53.0              4.0         4870.0   \n",
      "\n",
      "                      credit_history employment                    job  \n",
      "0  b'critical/other existing credit'     b'>=7'             b'skilled'  \n",
      "1                   b'existing paid'  b'1<=X<4'             b'skilled'  \n",
      "2  b'critical/other existing credit'  b'4<=X<7'  b'unskilled resident'  \n",
      "3                   b'existing paid'  b'4<=X<7'             b'skilled'  \n",
      "4              b'delayed previously'  b'1<=X<4'             b'skilled'  \n"
     ]
    }
   ],
   "source": [
    "# Step 3: Feature Selection\n",
    "numeric_features = ['duration', 'age', 'residence_since', 'credit_amount']\n",
    "nominal_features = ['credit_history', 'employment', 'job']\n",
    "selected_features = numeric_features + nominal_features\n",
    "\n",
    "# Create a new DataFrame with selected features\n",
    "df_selected = df[selected_features].copy()\n",
    "print(\"Selected Features:\")\n",
    "print(df_selected.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step4_md",
   "metadata": {},
   "source": [
    "Step 4: Preprocessing\n",
    "Perform any needed pre-processing on the chosen features, including: Scaling, Encoding, Dealing with NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "step4_code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T23:25:22.438474Z",
     "iopub.status.busy": "2025-11-19T23:25:22.438266Z",
     "iopub.status.idle": "2025-11-19T23:25:23.240123Z",
     "shell.execute_reply": "2025-11-19T23:25:23.239244Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Data Shape: (1000, 18)\n",
      "Target Shape: (1000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Decode byte strings if necessary\n",
    "for col in df_selected.columns:\n",
    "    if df_selected[col].dtype == object:\n",
    "        # Check if the first element is a byte string\n",
    "        if isinstance(df_selected[col].iloc[0], bytes):\n",
    "             df_selected[col] = df_selected[col].str.decode('utf-8')\n",
    "\n",
    "# Handle NaN values\n",
    "# Numeric: Impute with mean\n",
    "imputer_num = SimpleImputer(strategy='mean')\n",
    "df_selected[numeric_features] = imputer_num.fit_transform(df_selected[numeric_features])\n",
    "\n",
    "# Nominal: Impute with most_frequent\n",
    "imputer_cat = SimpleImputer(strategy='most_frequent')\n",
    "df_selected[nominal_features] = imputer_cat.fit_transform(df_selected[nominal_features])\n",
    "\n",
    "# Encoding Nominal Features\n",
    "# Using sparse_output=False for compatibility with pandas concatenation\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "encoded_nominal = encoder.fit_transform(df_selected[nominal_features])\n",
    "# Create DataFrame for encoded variables with proper column names\n",
    "encoded_nominal_df = pd.DataFrame(encoded_nominal, columns=encoder.get_feature_names_out(nominal_features))\n",
    "\n",
    "# Scaling Numeric Features\n",
    "scaler = StandardScaler()\n",
    "scaled_numeric = scaler.fit_transform(df_selected[numeric_features])\n",
    "scaled_numeric_df = pd.DataFrame(scaled_numeric, columns=numeric_features)\n",
    "\n",
    "# Combine all features\n",
    "df_processed = pd.concat([scaled_numeric_df, encoded_nominal_df], axis=1)\n",
    "\n",
    "# Process Target Variable\n",
    "target = df['class']\n",
    "if target.dtype == object and isinstance(target.iloc[0], bytes):\n",
    "    target = target.str.decode('utf-8')\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(target)\n",
    "\n",
    "print(\"Processed Data Shape:\", df_processed.shape)\n",
    "print(\"Target Shape:\", y.shape)\n",
    "#print(df_processed.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step5_md",
   "metadata": {},
   "source": [
    "Step 5: Splitting the Data\n",
    "Split the data into 80% training, 10% validation, and 10% test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "step5_code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T23:25:23.242659Z",
     "iopub.status.busy": "2025-11-19T23:25:23.242340Z",
     "iopub.status.idle": "2025-11-19T23:25:23.248223Z",
     "shell.execute_reply": "2025-11-19T23:25:23.247689Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (800, 18), (800,)\n",
      "Validation set shape: (100, 18), (100,)\n",
      "Test set shape: (100, 18), (100,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split: 80% Train, 20% Temp (Validation + Test)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(df_processed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split Temp: 50% Validation, 50% Test (which is 10% and 10% of total)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Validation set shape: {X_val.shape}, {y_val.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}, {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step6_md",
   "metadata": {},
   "source": [
    "Step 6: Training Classifiers\n",
    "Use the KNN-classifier model to train your data. Choose the best k for the KNN algorithm by trying different values and validating performance on the validation set.\n",
    "Classification Metrics: Print the accuracy score of your final classifier, print the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "step6_code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T23:25:23.250559Z",
     "iopub.status.busy": "2025-11-19T23:25:23.250257Z",
     "iopub.status.idle": "2025-11-19T23:25:23.560486Z",
     "shell.execute_reply": "2025-11-19T23:25:23.559541Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best k found: 19 with Validation Accuracy: 0.7300\n",
      "\n",
      "Final Test Accuracy: 0.7200\n",
      "Confusion Matrix:\n",
      "[[ 2 26]\n",
      " [ 2 70]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# Choose the best k\n",
    "best_k = 0\n",
    "best_accuracy = 0\n",
    "accuracies = []\n",
    "\n",
    "for k in range(1, 21, 2):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    val_pred = knn.predict(X_val)\n",
    "    accuracy = accuracy_score(y_val, val_pred)\n",
    "    accuracies.append((k, accuracy))\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_k = k\n",
    "\n",
    "print(f\"Best k found: {best_k} with Validation Accuracy: {best_accuracy:.4f}\")\n",
    "\n",
    "# Train final classifier with best k\n",
    "final_knn = KNeighborsClassifier(n_neighbors=best_k)\n",
    "final_knn.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on Test set\n",
    "test_pred = final_knn.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, test_pred)\n",
    "conf_matrix = confusion_matrix(y_test, test_pred)\n",
    "\n",
    "print(f\"\\nFinal Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
